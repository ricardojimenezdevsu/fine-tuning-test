Chapter 7. API Authentication and Authorization

In the previous chapter you learned how to threat model API-based systems and about the OWASP API Security Top 10. The Attendee API is ready to receive traffic from the outside world; however, how exactly is the consumer of the API identified? In this chapter we are going to explore authentication and authorization for APIs. Authentication tells us who the callee is and authorization tells us what they are allowed to do. We will begin by highlighting what authentication and authorization is for APIs. This leads to the importance of securing APIs and the potential limitations with using API keys and tokens. OAuth2 is a token-based authorization framework introduced in 2012 and has rapidly become the industry standard for securing APIs and determining what actions an application can perform against an API. A large part of this chapter will focus on OAuth2 and the range of security approaches offered for both end users and system-based interactions. Consumers of APIs will sometimes need to know details of the user they are acting on behalf of—to show how this can be achieved we will introduce OIDC. The chapter will illustrate the different approaches to security by looking to prepare the Attendee API for external usage by the CFP system.
Authentication Authentication is the act of verifying an identity. For the case of a user, the most traditional method is that the user presents their credentials in the form of a username and the password. It is now becoming more common for Multi-Factor Authentication (MFA) to be part of a standard login flow. MFA is useful to give higher levels of assurance that the user is who they say they are. For machine-to-machine authentication, credentials can be in the form of keys or certificates. By verifying the identity of the presented credentials, we know who is trying to communicate with our systems. Let’s look at this in the context of our Attendee service. The Attendee API contains personally identifiable information (PII) such as name and email address, which a user expects to be protected. In order to protect this information, the first step is to challenge and identify the caller of the API. Asserting this identity is called authentication. Once the caller is authenticated, the Attendee API establishes what the caller is allowed to access and retrieve: this type of entitlement checking is authorization. Figure 7-1 demonstrates the interaction with the Attendee API. The mobile application connects via the API gateway and queries the Attendee API. Another interaction follows a similar path from the CFP system, however the CFP system is owned by a third party. Let’s consider the options that we have for authenticating an end user (the mobile application user and the CFP system speakers) and a system-to-system interaction (the CFP system).
Figure 7-1. Securing our case study
End-User Authentication with Tokens The mobile application is acting on behalf of the attendee and retrieves and displays information about the attendees. In token-based authentication, the user would enter their username and password, which is exchanged for a token. The token issued depends on the implementation, but in the simplest case it could be an opaque string. The token is sent in the REST request as part of the Authentication Bearer header. Tokens are sensitive and it is important that the REST request is sent over HTTPS to secure the information in transit. Once a token is received as part of a request, it is inspected and checked to confirm the token’s validity. Figure 7-2 demonstrates a historically typical token lookup process where the token is stored in a database.
Figure 7-2. Server-side token lookup verification process
The token should have a limited lifetime—for example, an hour—and after the token expires, the user would need to obtain a new token. Tokens have the advantage that long-lived credentials, such as passwords, are not going across the network for every request to access resources. Things might seem ideal on the surface with tokens; however, a major disadvantage is the user having to enter the username and password into the application that is making calls to an API to retrieve their data. Also, when a token is placed into storage, looking up the token to check validity each time can be a performance concern and would need to be mitigated. What would be preferable is to use a token that has integrity and can be validated in-process.
Warning It is possible to access APIs using HTTP Basic, however, if a third-party application asks to access an API on your behalf, it means handing over your username and password.1 We recommend that you do not allow HTTP Basic to be used to access your APIs.
System-to-System Authentication In some situations an end user is not involved in the interaction and system-to-system communication is required. One option would be to use an API key, which does not conform to any particular standard. Whenever you do use an API key, it should be secure, meaning that it should be generated using a cryptographically secure random number generator and of an unguessable length. Typically API keys are 32-character-length strings (256 bits). If the API key is guessable (short and deterministic), this creates a vulnerability of a client being hacked. To access an API with an API key, you simply add the API key into a request header and send it to the endpoint.2 The API key is associated with an application or project, so it is possible to identify the requester.3 Using an API key is very similar to using a password. Figure 7-3 demonstrates an example of using an API key as part of a request.
Figure 7-3. External CFP system calling Attendee API with an API key
Why You Shouldn’t Mix Keys and Users Consider the scenario where a speaker is using the CFP system, owned by a third party, and the CFP is requesting an update to the email address associated with that user’s data. Just because the CFP system is using an API key and can be identified does not mean that this third-party system should be able to assert who the end user is or who they are acting on behalf of. This puts trust of the entire system in the hands of the third party. A solution to this would be that the CFP system also passes the user’s username and password (using HTTP Basic) along with the API key to allow the Attendee service to authenticate the user. However, as we have already warned, this means that the user must hand their username and password for the Attendee service to the CFP system, which is undesirable. The ideal scenario would be a situation where the CFP system can call the Attendee service, but any request performed on behalf of a user by the CFP system does not require sharing credentials and is done with the user’s specific approval. The solution to this problem is in essence the use of OAuth2.
OAuth2 OAuth2 is a token-based authorization framework and has been around since 2012. It is the replacement for OAuth, which is still around—however, it is used in very few places. OAuth2 allows a user to consent that a third-party application can access their data on their behalf. The consent that the user gives is the authorization—they are allowing or denying the access. OAuth2 removes the need for a user to hand over their credentials to the third party, which gives the user control over their data. This makes OAuth2 appealing as it supports the challenges faced in the previous section. In order to explore OAuth2 further, it is important to first understand the different roles within the OAuth2 specification. The definitions have been taken directly from the OAuth2 specification: Resource Owner An entity capable of granting access to a protected resource. When the resource owner is a person, it is referred to as an end-user.Authorization Server The server issuing access tokens to the client after successfully authenticating the resource owner and obtaining authorization. Most identity providers, such as Google or Auth0, will be OAuth2 authorization servers.
Client An application making protected resource requests on behalf of the resource owner and with its authorization.Resource Server The server hosting the protected resources, capable of accepting and responding to protected resource requests using access tokens.
Authorization Server Role with API Interactions The authorization server has two endpoints: The authorization endpoint is used when a resource owner needs to authorize access to protected resources.The token endpoint is used by the client to get an access token.
If the Attendee service was called directly by the client, then the Attendee service would be the resource server as it is hosting protected resources. However, a resource server does not need to be an individual application; it could represent a complete system. One popular pattern is to use the API gateway as a resource server, as shown in Figure 7-4. The two clients, the mobile application and the CFP system, are calling the Attendee service via an API gateway. There could be multiple services behind the API gateway but for the client the API gateway would still be the resource server as it is hosting the protected resources. The two resource owners in this case are the attendees using the mobile app and the speakers using the CFP system.
Figure 7-4. API gateway as the resource server
JSON Web Tokens (JWT) JavaScript Object Notation (JSON) Web Tokens are an RFC standardized token format that is the de facto standard token for OAuth2. A JSON Web Token, also known as a JWT (pronounced “jot”), consists of claims and these claims have associated values. JWTs are structured and encoded using standards to ensure the token is unmodifiable and additionally can be encrypted. They are especially useful in the transfer of information in “space constrained environments such as HTTP Authorization headers”. Here is an example JWT: { "iss": "http://mastering-api/", "sub": "18f913b1-7a9d-47e6-a062-5381d1e21ffa", "aud": "Attendee-Service", "exp": 1618146900, "nbf": 1618144200, "iat": 1618144200, "jti": "4d13ba71-54e4-4583-9458-562cbf0ba4e4" } In this example the claims are iss, sub, aud, exp, nbf, iat and jti—these are all reserved claims in the JWT RFC. Reserved claims have a special meaning. They are not mandatory in a token, however they offer a starting point for a minimum amount of information. Looking at our example token, let’s list what the claim abbreviations are and how they are typically used: iss (Issuer) The authority that issued the token. This is normally an identity provider (e.g., Google or Auth0).sub (Subject) A unique identifier to identify the principal of the JWT. In the case of the mobile application that is acting on behalf of the user, this would be attendee (e.g., Matthew Auburn); if this was a server-to-server connection, this may be the application (e.g., the CFP System).4 The subject value does not follow any format, and if you are defining what the subject should be, you must decide if it should be unique within your system or universally unique (e.g., using a UUID).aud (Audience) Who this token is intended for.exp (Expiration time) When the token expires (45 minutes after being issued in this case).nbf (Not before) Token should not be used before this time (same time as the issued time in this case).iat (Issued at) The time the token was issued.jti (JWT ID) A unique identifier for the JWT.
Note Tokens can contain more information such as preferred name, email of the user, claims about the issuing party, and which application requested the token. For high-security APIs it is common that the authentication method to the authorization server is a claim, which can be used to check if MFA was used by the resource owner to authenticate themselves.
Encoding and verifying JSON Web Tokens There are two popular encoding mechanisms for JWT, which have their own format: JSON Web Signatures (JWS) provides integrity to a JWT. The contents of the token are visible to anyone who receives the token; however, the claims are digitally signed, which ensures that if the contents of the token are changed, the token is immediately invalid.JSON Web Encryption (JWE) provides integrity but is also encrypted. This means that the contents of the token cannot be examined.
Note Generally, when JWT is used, that implies JWT using JWS, and Encrypted JWT means JWT using JWE.The most common mechanism used is JWS, where the digital signing is performed using a private key. The public key is used by the receiver of the token to validate that the token was signed by the specific issuing party. The public key is freely shared with any party that needs to verify the integrity of the token.
Warning If you’re using JWT with JWS, you should not insert confidential data into the claim values. JWS provides integrity to the claims; however, anyone who has the JWT can read the claims. To ensure the JWT can’t be read, use JWE.JWTs are a great option for a token format. API services consume the JWT, validate it by verifying the signature, and do not need to look up a token in a database. As the access token will be from an authorization server that is (most likely) under your control, you can add all the information you expect/require to your JWT. When the JWT is received, there are multiple parts to verify. First, the signature is checked to confirm that it was issued from the expected party and has not been modified or tampered with. Then other claims in the token should be validated, such as checking that the token has not expired (exp claim) or that the token is not used before it is allowed (nbf claim). All tokens that are issued should be short-lived; long-lived tokens are a risk if they are lost or stolen. On the topic of long-lived assertions, the NIST (National Institute of Standards and Technology) Digital Guidelines state: Long-lived assertions have a greater risk of being stolen or replayed; a short assertion lifetime mitigates this risk.There is no official standard for how long a short-lived or long-lived token should be valid for. The typical suggested lifetime of a short-lived token is between 1 and 60 minutes, and a long-lived token is from one year to ten years. It is suggested that you keep the lifetime of tokens as short as possible. There are many positives to using JWTs for an access token. Now let’s look at their usage within OAuth2.
Terminology and Mechanisms of OAuth2 Grants OAuth2 is designed to be extensible. The official OAuth2 spec was released in 2012 with four grants, and since then additional grants and modifications have been approved to extend its usage. This is made possible as OAuth2 presents an abstract protocol, shown in Figure 7-5: The client requests authorization from the resource owner.The resource owner will grant or deny the client access to their resources.The client will ask for an access token from the authorization server for the authorization it has been granted.The authorization server will issue an access token if the client has been authorized by the resource owner.The client makes a request for the resource to the resource server, which in our case is the API. The request will send the access token as part of the request.The resource server will return the resource if the access token is valid.
Figure 7-5. Abstract protocol flow
This abstract protocol about how OAuth2 grants should work highlights that the resource owner has control over their own resources. The client is requesting authorization from the resource owner—i.e., “can I (the application) access your resources on your behalf?” The way in which authorization is given is not important. What is essential is that the resource owner has the opportunity to grant or deny access. When requesting a resource from the resource server (i.e., calling the API), how the client obtained the access token does not matter. As long as the request contains a valid access token, the resource server will issue the resource. Each step is isolated and does not require information about the previous step. This is why there are different grants for different scenarios, as they have their own implementation to ensure that these steps are secure for that environment.
ADR Guideline: Should I Consider Using OAuth2? It is important that you understand the reasons to adopt using OAuth2 and whether it is even the right choice for you. To help with this decision, use this ADR Guideline (see Table 7-1) to help you determine what is right for you and the conversations you may want to have. Table 7-1. ADR Guideline: Do I need to use OAuth2? Decision Should OAuth2 be used or is there another standard for authentication and authorization that is preferred for the operating environment?Discussion Points When you start working with APIs, you have the opportunity to decide or influence the security mechanisms for them: Examine the current security requirements and how things might potentially change. For example, are APIs just used within a control plane or are they also used outside of a control plane/potentially with third parties?What security model are you expected to support? Have external integrators requested that you use a certain security model?Do you need to support multiple authentication and authorization models? This is important if you are looking to migrate from an existing authentication model to another.
Recommendations Using OAuth2 will provide the maximum compatibility with other API users. It is an industry standard with documentation and client libraries that ease integration. OAuth2 supports both the end user and system-to-system cases.
Authorization Code Grant The Authorization Code Grant (Auth Code Grant) is an implementation of an OAuth2 grant; it is an implementation of the abstract protocol that you saw previously in Figure 7-5. This is a most well-known grant, and you will likely have used it without realizing you did.5 The typical use case for the Authorization Code Grant is a website backed by a server, which is not publicly available to the internet (i.e., it can protect a secret). A client application that can protect a secret is called a confidential client. Figure 7-6 describes in more detail how the grant works: The client application directs the web browser (the User Agent in the diagram is a web browser) to an authorization server. The redirect to the authorization server will include the identification of the client (a client ID), and as part of the redirect it also has what grant is being used (in this case the Authorization Code Grant is known as code).The authorization server asks the resource owner (end user) to identify themselves. The authorization server needs to know who the resource owner is, so the resource owner will need to authenticate to the authorization server. The authorization server is then able to get consent from the resource owner if they grant authorization to the client application. (Steps A and B of the Authorization Code Grant are all about the authorization request; this is shown as a single step (A) in the abstract protocol from Figure 7-5.)Assuming authorization is granted, an authorization code is passed to the client application, via the User Agent. (This step matches to Step B of the abstract protocol where it shows the authorization grant returned.)The client then requests an access token from the authorization server presenting the authorization code. The authorization server cannot just accept the authorization code from anyone. The client application must authenticate itself to the authorization server by using a secret that is known to the authorization server and the client application. (In the abstract protocol this is Step C where the authorization grant is sent to the authorization server to be exchanged.)If the client application successfully authenticates and presents a valid authorization code, it is granted an access token. (This step lines up with Step D in the abstract protocol where the access token is issued.)
Figure 7-6. Authorization Code Grant
This solution works really well and was the default model for web applications. However, the world of websites has evolved, and Single Page Application (SPAs) now exist. SPA websites are JavaScript-based and run in the user’s browser, which means that the source code is fully available for the user to look at. It means also that an OAuth2 client SPA cannot protect a secret and is known as a public client, so using Auth Code Grant as it stands is not possible.
Authorization Code Grant (+ PKCE) This is when you would use Authorization Code Grant + PKCE, which allows you to use OAuth2 for SPA applications. PKCE stands for Proof Key for Code Exchange and is used to mitigate interception attacks. Within the Auth Code Grant + PKCE grant, two additional parameters are needed: one for the authorization request, which is the code_challenge, and one for the access token request, which is the code_verifier. The code_verifier is a cryptographically random string generated by the client, and the code_challenge is the hashed value of the code_verifier. When the client application initiates the request to the authorization server, it sends the code_challenge, and when an access token is requested, the authorization code is presented along with the code_verifier. The authorization server can hash the code_verifier to check that it matches the code_challenge used to initiate the token request. This extension makes the grant more secure as only the original client should have the code_verifier; this prevents attacks where an authorization code could be intercepted and swapped for an access token. We can see this grant in action in Figure 7-7. The authorization request is made and the code_verifier is sent to the authorization server. In the diagram t(code_verifier) is the transformation of the code_verifier to the code_challenge and t_m is the transformation method (as described previously, this is a hash).Like in the Authorization Code Grant, an authorization code is returned.The client requests the access token by sending the authorization request, which is the authorization code and the code_verifier. No client secret is sent as this is a public client.The access token is then issued to the client application.
Figure 7-7. Authorization Code Grant + PKCE
You may be looking at these steps and wondering how this maps back to the Authorization Code Grant without PKCE. The diagram looks different from Figure 7-6, but the only real difference is the first step, Step A. In Step A of Figure 7-7, it is all about the authorization request (like in the abstract protocol Step A), and the process will be the same as in the Authorization Code Grant in Steps A and B.
Tip PKCE must be used for public clients. However, you can use PKCE for confidential clients as well as for additional protection.The Authorization Code Grant and its PKCE extension will work in the most common scenarios for your public and confidential clients when you have an end user in your case.
Case Study: Accessing Attendee API with the Authorization Code Grant There are two client applications for accessing the Attendee API. Both of these applications will use the Authorization Code Grant to access the Attendee API on behalf of users (the resource owners). The External CFP system is a confidential client. The client can maintain a secret, which means that Authorization Code Grant can be used. The mobile application is a public client, and it is not able to maintain a secret, therefore Authorization Code Grant + PKCE must be used. The steps for the External CFP system and the mobile application requesting an access token and using them to access the Attendee service are shown in Figure 7-8. This also highlights that using PKCE does not change the high-level steps taken or the user’s journey.
Figure 7-8. Authorization Code Grant applied to our case study
Refresh Tokens It is good practice to issue tokens that are short-lived; however, asking a user to reenter their username and password would soon become a jarring experience. A refresh token is a long-lived token used by the client to request additional access tokens when the previous token expires. Refresh tokens are requested as part of the authorization request, meaning the end user is not involved in requesting further access tokens. As part of the latest security best practices, the detection of a refresh token used twice immediately revokes the active refresh token. Refresh tokens are an additional credential and long-lived, so it is important that these are kept secure and not leaked. If at any point a client needs to be denied access, including if the resource owner does not want the client to have further access to their resources, the refresh token can be revoked. The next time the client application requests a new access token (which are short-lived) they will be stopped. This does mean that there can be a window when a client has a valid access token but should not have access. This is why it is important to have short-lived tokens.
Client Credentials Grant The client for the Client Credentials Grant is a confidential client as it needs to maintain a secret. As this is for machine-to-machine communication, the connection is set up in advance and the access (what the client is authorized to do) should be pre-arranged. The process of the client obtaining an access token is very straightforward as shown in Figure 7-9:6 The client application authenticates to the authorization server and requests an access token. The client also identifies the grant being used, which is client_credentials.The authorization server returns an access token if the client application successfully authenticates.
Figure 7-9. Client Credentials Grant
There are no additional steps as there is no resource owner to give permission. The client is acting on its own behalf so only is required to identify itself.
Case Study: Accessing Attendee API from the CFP system with Client Credentials Grant The External CFP system produces a report every three months to show how many attendees go on to submit talks and become speakers. This report generation is not on behalf of an attendee but instead happens for the External CFP system. The client (External CFP system) is registered into the authorization server.7 In the Attendee service the client is added into a list of clients that can access the service and is configured to be able to read information about attendees and query which users have submitted talks—this is the pre-arranged access. When the client wants to access the Attendee API, it will request an access token from the authorization server and then use the access token when it calls the Attendee API. You have now seen how to use OAuth2 for machine-to-machine communication, but what if your case has not been covered so far?
Tip Refresh tokens are not used with the Client Credentials Grant; instead, the client requests a new access token.
Additional OAuth2 Grants There are more OAuth2 grants available than just the previous two discussed. The other standardized grants available are listed here, but we will not explore them in further detail: The Device Authorization Grant is used for devices that have limited input or lack a browser. This makes it useful for IoT devices, such as your smart fridge or a Raspberry Pi project.Implicit Grant was used commonly for SPAs, but it has been replaced by the Authorization Code Grant + PKCE.Resource Owner Password Credentials Grant was historically used as a stepping stone from HTTP Basic to get client applications off the ground using OAuth2. It is recommended not to use this grant.
ADR Guideline: Choosing Which OAuth2 Grants to Support As we have seen, there are many OAuth2 grants. It is important to pick the grant that is right for your case or the grants you want to support. The ADR Guideline in Table 7-2 provides discussion points and considerations you should think about before picking your grant. Table 7-2. ADR Guideline: Which OAuth2 Grants Decision Which OAuth2 Grants should be supported?Discussion Points Determine what types of clients will be interacting with your APIs: Do you need to support IoT devices and the Device Authorization Grant?Do you have older clients that are SPAs that only support the Implicit Grant?Should you outright forbid the use of the Resource Owner Password Credential Grant?
If you already have a security model for authentication and authorization, should you move to OAuth2? Which grant best represents your interaction model?Will the clients be able to migrate to the grant? If they are under your control or you have a small number of third parties, this will be significantly easier to start getting third parties to migrate.Should all new onboarded clients use the new OAuth2 Grant?
Recommendations We recommend that you use OAuth2 and use only the grants you need and add more if required. If you have a security model in place that works and many paying customers, it may not be feasible to force them to migrate over to use OAuth2. However, you may have to evolve your security architecture to use OAuth2 to be more standard, as this can also be a request from third parties so they do not need to build a custom interaction for your security model. Starting with the Client Credentials Grant is often the easiest way to introduce OAuth2 into an API system.
OAuth2 Scopes Scopes are an important mechanism in OAuth2 and are effectively used to limit the access of a client acting on behalf of a user. When a user first authenticates, the end user receives a consent screen, which will state what the client is requesting access to do. For example, “Application would like to read appointments in your calendar” and “Application would like to book meetings in your calendar.” The end user is in control and can restrict what actions the client can perform on their behalf.
Case Study: Applying OAuth2 scopes to the Attendee API Let’s explore a practical example to show scopes for modeling attendees using some endpoints. To help with this example, let’s imagine that the legacy conference system has two endpoints exposed as well: Attendee API GET – /attendees—Get a list of attendeesGET – /attendees/{attendee_id}—Get details of an attendeePOST – /attendees—Register a new attendeePUT – /attendees/{attendee_id}—Update attendee information
Legacy Conference API GET – /conferences—Get a list of conferencesPOST – /conferences—Create a new conference
The External CFP application needs to only access the Attendee API, so as a resource owner you do not want the External CFP to access conference information. There should be a separation where you can authorize the External CFP system to just the Attendee API. Two scopes are created: the Attendee scope and a Conference scope. This is shown as the HTTP Method – endpoint – scope. Attendee API GET – /attendees – AttendeeGET – /attendees/{attendee_id} – AttendeePOST – /attendees – AttendeePUT – /attendees/{attendee_id – Attendee
Legacy Conference API GET – /conferences – ConferencePOST – /conferences – Conference
This achieves the separation of conferences and attendees, however it is possible to take this a step further and differentiate between read and write operations: Attendee API GET – /attendees – AttendeeReadGET – /attendees/{attendee_id} – AttendeeReadPOST – /attendees – AttendeeAccountPUT – /attendees{attendee_id} – AttendeeAccount
Scopes don’t have a defined standard, however they are typically used as a coarse-grained separation within an API. Scopes must make sense to the end user, as they are going to need to consent to their usage. Once the resource owner grants authorization to a resource, this information needs to be used by the resource server to enforce this. When using access tokens in a JWT format, a claim is normally added to the JWT; e.g., "scope": "AttendeeRead AttendeeAccount.8 This will have the list of all the scopes that have been authorized. Scopes are not mandatory for OAuth2, though it is very useful and something that you should consider for coarse-grained authorization.
Authorization Enforcement Authorization needs to be enforced as this is fundamental in API security. Two of the most common security authorization issues listed in the OWASP API Security Top 10 are Broken Object Level Authorization (BOLA) and Broken Function Level Authorization. BOLA is when a user is able to request information for an object that they should not have access to, often discovered by tampering with a resource ID. Broken Function Level Authorization is when the user can perform tasks they are not authorized to do, for example executing an administration-only endpoint as a standard user. Authorization is typically based on some sort of entitlements. This is popularly enforced using Role Based Access Control (RBAC). Though the exact entitlement choice is a detail, some sort of access control should exist and it is important that every endpoint has an authorization check before fulfilling the request. When you look at authorization with OAuth2, you must keep in mind that scopes are used to specify what a resource owner has stated regarding the range of actions a client can perform. This does not mean that the client should have access to all end-user data. For the Attendee service there could be different actions that are possible, such as admin rights to manage attendees and view-only rights on attendees. An attendee may only have permission to read the attendees’ profile description; however, a client may ask for permission to read attendees’ information and to manage attendees. A user may grant access to the client to perform these tasks on their behalf; however, the user themself may not have access. This overlap of authorization is highlighted in Figure 7-10.
Figure 7-10. Venn of authorization
Scopes are useful for an API gateway to enforce scope authorization and to reject requests when a client does not have the correct scope to access an API.
Introducing OIDC OAuth2 provides a mechanism for the client to access APIs using authentication and authorization. A common requirement is for the client to know the identity of the resource owner. Consider the External CFP system. It will need to store data about the speaker, but OAuth2 grants do not provide a way to obtain the identity of the end user. This is the purpose of OpenID Connect (OIDC); it provides an identity layer. This layer builds on top of OAuth2, by having the OAuth2 authorization server implement additional functionality. The functionality required turns the OAuth2 authorization server into an OpenID provider as well. It is now possible for a client to request information about the user by using a special scope called openid. This scope is requested along with any the scopes required for any access tokens. Using the openid scope provides the client with an ID token, which is a JWT that contains claims about the user. The ID token returned when using just the openid scope contains a very limited amount of information about the user. The only claim that identifies the user is the subject claim, which is a unique ID of the user and must never change (usually this is a UUID). Having just a unique ID about the user is not usually enough for the client. That is why OIDC specifies additional scopes that can be added to the request to get information in the ID token: profile name, family_name, given_name, middle_name, nickname, preferred_username, profile, picture, website, gender, birthdate, zoneinfo, locale, and updated_atemail email and email_verifiedaddress addressphone phone_number and phone_number_verified
You can end up with a very rich ID token that contains a lot of information about the user. These scopes are used in the context of ID tokens—you would not see these scopes in your access token as you saw in “OAuth2 Scopes”. Three flows are declared by OIDC: Authorization Code Flow, Implicit Flow, and Hybrid Flow. The OIDC specification calls steps to acquire an ID token “flows.” The recommendation is to use the Authorization Code Flow for the same reasons as the Authorization Code Grant (+ PKCE)—it is more secure. Many people think that OAuth2 and OIDC are the same thing and will refer to OIDC being used to access APIs. The reality is that they are not the same; they are two distinct things. OIDC has its role, providing user identity to clients; however, it does not provide access to APIs. If OIDC is something that you need, then you should be sure that your identity provider has support for it. Do not try to build your own identity layer.
Warning Never substitute ID tokens for access tokens. This is very dangerous practice as ID tokens are not intended for this purpose. They are long-lived tokens with the purpose of providing information about the user to a client. They are not for accessing resources.
SAML 2.0 In enterprise environments it is common to use SAML 2.0, often referred to as just SAML. SAML (Security Assertion Markup Language) is an open standard that transfers assertions. It is often used for single sign on, and the assertions that are transferred are user identities. SAML is popular within the enterprise world as it is used to allow employees to sign on to external applications. SAML is not aligned to be used by APIs in its raw form. However, there does exist an OAuth2 extension: Security Assertion Markup Language (SAML) 2.0 Profile for OAuth 2.0 Client Authentication and Authorization Grants. This extension allows a client to request an access token using SAML, assuming that the authorization server has implemented the functionality. You should be aware of this if SAML is something that you need to use as part of a migration to OAuth2.
Summary In this chapter we have explored the importance of securing APIs and robust industry standards to achieve this: Authentication establishes the identity of the resource owner, which in APIs is either an end user or an application performing system-to-system communication.OAuth2 is the de facto standard for securing APIs and often leverages JWT as part of the bearer header. JWT tokens are often encoded and signed to ensure they are tamper free.Different OAuth2 grants support different scenarios. The most common are the Authorization Code Grant + PKCE and the Client Credentials Grant.Refresh tokens help to smooth out the end-user experience of needing to keep asking the user to enter a username and password.OAuth2 scopes help to provide coarse-grained authorization and allow the end user to configure the access of a client.OIDC is used when the client requires information about the end user. OIDC provides basic information about the authenticated user and can optionally provide additional details.
Fundamentally, you should now understand how you can identify an API callee and how you can secure your own APIs. However, this is not the end of the journey, as the majority of software architectures don’t stay still. You will learn about evolutionary architecture with APIs in the next chapter.
1 If you do not know what HTTP Basic is, refer to the spec rfc7617. 2 The request header is either a custom header (e.g., X-API-KEY: My_super_secret_API_Key) or the authorization header. 3 Google has a good piece on this here. 4 An email or username is normally not a good choice as users modify these over time. Having a consistent identifier is simpler to manage. 5 A typical scenario is when you are using LinkedIn and LinkedIn asks to access your GMail contacts. LinkedIn redirects you to Google and you log in to your Google account. You are then presented with a message saying “LinkedIn would like to access your email contacts.” After you accept, LinkedIn can access your emails. 6 If you want to look further at adding even more security to the client application getting access tokens, see RFC8705. This specification uses Mutual TLS instead of secret strings to obtain access tokens. 7 It is fine to have a client registered for multiple grant types; the subject of the callee will be different depending on the grant used. As we see here in the client credentials, the subject is the client making the request and not on behalf of a resource owner. 8 This may be an array—comma-separated, or like this case, space separated.
Part IV. Evolutionary Architecture with APIs This section explores how to evolve the architecture of a system or series of systems using APIs. This includes evolving existing legacy applications toward API-based, service-oriented architectures, and also using API infrastructure for evolving or replatforming a system for effective deployment into a cloud environment. Chapter 8 explores redesigning monolithic applications toward an API-driven architecture. In Chapter 9, you will learn how to use API infrastructure to evolve your current systems toward cloud platforms. Chapter 10 provides a summary of key lessons you have learned throughout the book. This chapter also presents ways in which you can continue to evolve the case study and advance your learning about API architecture. 