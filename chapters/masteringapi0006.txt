Chapter 6. Operational Security: Threat Modeling for APIs

At this stage you have explored the full API Lifecycle—taking into consideration design and testing, options for deployment, and strategies for releasing APIs. The Attendee API may appear like it is ready to be exposed to external systems. APIs are quick to build, tricky to design for future compatibility, and even harder to secure. The truth is that developers and architects focus on delivering functionality, and security is often not considered until toward the end of a project. In this chapter, you will see why security is important and how not having proper security in place can damage your reputation and be expensive. You will learn how to examine a system’s architecture for security weaknesses and determine the threats that could be encountered within a production environment. Of course, you won’t be able to identify all the threats—attackers are devious, and the threat landscape continually evolves—but the critical skill for architects is to be able to “shift left” the design and implementation of security concerns, both for themselves and for the wider development teams.1 The earlier you consider security within your software development lifecycle (i.e., the further left this can be shifted), generally speaking, the easier and more cost effectively you can adapt to the evolving threat landscape. This will help you make informed decisions when engaging in the security design for APIs. In “Enforce Security: Transport Security, Authentication, and Authorization”, we reviewed how communication within a control plane or system is possible to secure using mTLS. However, once “external” systems outside of the control plane’s reach are introduced, a new approach is required.
Case Study: Applying OWASP to the Attendee API You will begin your journey toward designing secure systems with an introduction to threat modeling. You will then explore how to conduct a threat model exercise, using the Attendee service and API as an example, as shown in Figure 6-1.
Figure 6-1. The Attendee API that will be used in the threat modeling exercise
A core component of threat modeling is looking for potential security weaknesses, so you will explore the OWASP API Security Top 10, which you can use both as a source of inspiration when hunting for issues and as a source of mitigations when you are attempting to address the threats found. By the end of the chapter you will understand what threat modeling is and how you can apply this to your own projects.2 Open Web Application Security Project (OWASP) is a nonprofit foundation that works to improve the security of software. The most well-known project by OWASP is the OWASP Top 10; this project is a list of the most critical security risks faced by web applications. In 2019 OWASP produced a new top 10 list—this was the API Security Top 10. The list is based on the work of security experts who examined security breaches and bug bounty programs, and penetration testers also gave their input on what should be in this top 10. This is not an exhaustive list of all the threats you will face. However, you should keep them in your mind when looking at how your API might be exploited. These lists are updated periodically, so it is important to look for changes and updates to the top 10 as they evolve.
The Risk of Not Securing External APIs Though security has become more appealing and been brought into the limelight as a topic,3 it has struggled to gain the same popularity as technologies such as machine learning, big data, and quantum computing. For the majority of software professionals, security is not always at the forefront of their minds. Developers are focused on coding business solutions, SRE teams ensure the plant is running, and product owners focus on the planning of new valuable features. Security is often deferred, and if you are fortunate to have a security team, then it may get delegated to them. The perceived value for the customer is (normally) not in the security controls implemented but rather in the service that your system provides. Security breaches can have catastrophic impact: there is a usually significant risk to an organization’s reputation. Financially, the impacts are huge: “the average cost of a cyber-breach to a publicly traded company was $116 million” and the average cost of a data breach for an organization in 2021 was $4.24m, up 10% from the previous year. Following are a few example headlines of security breaches that have had a huge cost, both financially and socially: Databases Leak Data Of 419 Million UsersData Breach Impacts 143 Million AmericansSecurity Breach Exposes personal information of 47 Million Users$17.5 million settlement over data breach106m customer records stolen and issued a $80m fine£16.4m fine for failings surrounding a cyber-attack
The last two articles are interesting, as the regulators issued penalties for breaking regulatory rules or not responding appropriately. It is important to look at your operating environment to see what requirements exist for client data governance. A fair assumption from users is that appropriate measures are being taken to protect their privacy and data; if not, your organization is accountable. One such regulatory requirement is the General Data Protection Regulation (GDPR), which gives greater control to individuals over their personal information. These can carry serious financial penalties if not followed. Currently, the biggest fines issued for breaking GDPR include Amazon with a £636m fine and WhatsApp with a €225m fine.
Warning The accountability of an organization goes beyond APIs and systems developed by the organization. Vendor products and open source software present real challenges if not carefully managed. Ensure that vendor products are held to the same standard that you would hold your own software development standards to. Open source software vulnerabilities can be wide reaching. Ensuring that an organization tracks Common Vulnerabilities and Exposures (CVEs) and is able to rebuild impacted software is critical.
Threat Modeling 101 Threat modeling is a “technique you can use to help you identify threats, attacks, vulnerabilities, and countermeasures that could affect your application”. To use a real-world analogy, if you were conducting a threat modeling exercise for your house or apartment, you would identify things like points of entry (doors, windows) and whether you have given a front door key to a neighbor. This approach is beneficial as it is only possible to mitigate security risks once the threats have been clearly identified. It also helps to prioritize efforts to improve security and avoid meaningless efforts or security theater. To continue the house example, it would not be beneficial if you spent a large amount of money on a steel reinforced front door only to leave the key under your doormat or the flower pot right outside. Threat modeling is a process that should be integrated into your entire software development lifecycle. Ideally it is conducted at the beginning of a project and is continually revisited as the system and architecture evolves. The good news is that there are a number of well-defined methodologies for threat modeling. In this book we will use the STRIDE methodology designed by Praerit Garg and Loren Kohnfelder at Microsoft. You’ll learn more about this methodology later in the chapter. Threat modeling of software systems has historically been performed using data flow diagrams (DFDs).4 DFDs capture the dynamic (data flow) aspects of a system, while C4 models primarily capture the static (structural) aspects of the system. DFDs are simple to understand and data-centric, which makes it easy to see how data flows through the system. The core components for DFDs are: External entities These are applications/services that are not part of your system. In our case this would be the mobile application.Processes An application/task that is in our domain, such as the API gateway.Datastores A location where data is stored. For the case study, this would be the database.Data flows Connection that represents the flow of data, such as the mobile application to the API gateway.Boundaries A privileged or trust boundary to show a change in trust levels. A boundary for the case study would be the internet boundary between the mobile application to the API gateway.
As part of our threat modeling, we have created a DFD as shown in Figure 6-2.
Thinking Like an Attacker Architects and development teams can at times be reluctant to consider security issues, as they believe this is the job of a specialist team. However, who better than the people designing and building the key structural components of a software system to identify and understand potential weaknesses? Architects and security experts can then collaborate on addressing these problems and work together to explore different angles of attack. The good news is that to conduct a threat modeling exercise, you do not need to be a security expert yourself, but you need to think like an attacker or bad actor. Thinking like an attacker is often easier than you think, as you do it all the time (just by asking yourself “what would the attacker do?”)! For example, when you park your car in the evening, what do you do with your car keys? Do you leave them in the car? Probably not if it is left on the street, though you may if it is in a garage. You could leave the keys by the front door. However, someone could use a coat hanger through the letter box to take your keys, or, if a wireless car, the attacker could use signal amplification. So do you take them upstairs? And with the rise of electronic locking systems and immobilizers, do you put them in a Faraday cage? What you are doing here is looking at a situation and evaluating the threat and weighing up the risk. You now need to apply this approach to designing software systems, with a little help from existing well-defined methodologies.
How to Threat Model As with many methodologies within software design and development, there are well-defined goals, approaches, and techniques to threat modeling that architects and engineers have refined over the years. The high-level approach to threat modeling is: Identify your objectives—Create a list of the business and security objectives. Keep them simple (e.g., avoid unauthorized access).Gather the right information—Generate a high-level design of the system and ensure you have the right information. To be able to understand how your systems work and work together, this will include having the right people involved in the conversation.Decompose the system—Break down your high-level design so that you can start to model the threats. This may require multiple models and diagrams.Identify threats—Systematically look for threats to your systems.Evaluate the risk of the threats—Prioritize threats to focus on the most likely ones, then identify mitigations to these likely threats.Validate—Ask yourself and your team if the changes in place have been successful. Should you perform another review?
Let’s now explore these steps in more detail, using the case study as the system that you want to perform a threat modeling exercise on.
Step 1: Identify Your Objectives The first step of threat modeling is to identify your objectives; this is the driver for performing the threat modeling. When deciding objectives for your own systems, you should focus on what security goals you are trying to achieve. These goals should be sourced from across your entire organization, and not just your team and the InfoSec teams. Security objectives are often driven from business goals, such as avoiding data leakage to prevent being sued or being compliant with regulations like GDPR. If these are just sourced from your immediate area, then you do not have a complete picture of the most important issues that face your organization. Your objectives for the Attendee service is to prepare the API for external consumption by third parties by ensuring that the OWASP Top 10 are mitigated.
Step 2: Gather the Right Information Once you have the goals in mind, Step 2 of threat modeling is acquiring the information about how the system works. With threat modeling, you need to bring in experts on each area of the system and associated codebases or products. This is to ensure that you understand how everything works and that no hidden assumptions are made. For the Attendee API, this will require bringing in members of the team who work across all of your components; mobile, gateway, databases, and Attendee service.
Step 3: Decompose the System The third step of the threat modeling process is to create a diagram of the system that shows the component interactions with the flow of data. The information gathered collaboratively is then used to create the DFDs. Creating diagrams can be time-consuming, so we recommend using dedicated threat modeling tooling. For the case study data flow diagram, shown in Figure 6-2, we used the Microsoft Threat Modeling Tool, although other tools are available.5
Figure 6-2. Data flow diagram
Step 4: Identify Threats—Taking This in Your STRIDE The fourth step of threat modeling is all about looking at the threats to the system. When you start looking at the data flow diagram, it is important to keep your threat modeling objectives in mind, otherwise it can be tempting to go off on a tangent. The benefit of using the dedicated Microsoft Threat Modeling Tool is that it can conduct some automated analysis for you using the STRIDE methodology. The generated list is not complete, but it can be used as a starting point. The list of generated threats for our Attendee API System is seen in Figure 6-3. In this case the tooling has found 27 potential threats.
Figure 6-3. Data flow diagram threat analysis
The STRIDE acronym stands for:6 Spoofing Breaching the user’s authentication information. In this case, the hacker has obtained the user’s personal information or something that enables him to replay the authentication procedure. Spoofing threats are associated with a wily hacker being able to impersonate a valid system user or resource to get access to the system and thereby compromise system security.Tampering Modifying system or user data with or without detection. An unauthorized change to stored or in-transit information, formatting of a hard disk, a malicious intruder introducing an undetectable network packet in a communication, and making an undetectable change to a sensitive file are all tampering threats.Repudiation An untrusted user performing an illegal operation without the ability to be traced. Repudiability threats are associated with users (malicious or otherwise) who can deny a wrongdoing without any way to prove otherwise.Information disclosure Compromising the user’s private or business-critical information. Information disclosure threats expose information to individuals who are not supposed to see it. A user’s ability to read a file that she or he was not granted access to, as well as an intruder’s ability to read the data while in transit between two computers, are both disclosure threats. Note that this threat differs from a spoofing threat in that here the perpetrator gets access to the information directly rather than by having to spoof a legitimate user.Denial of Service Making the system temporarily unavailable or unusable, such as those attacks that could force a reboot or restart of the user’s machine. When an attacker can temporarily make the system resources (processing time, storage, etc.) unavailable or unusable, we have a denial of service threat. We must protect against certain types of DoS threats for improved system availability and reliability. However, some types of DoS threats are very hard to protect against, so at a minimum, we must identify and rationalize such threats.7Elevation of privilege An unprivileged user gains privileged access and thereby has sufficient access to completely compromise or destroy the entire system. The more dangerous aspect of such threats is compromising the system in undetectable ways whereby the user is able to take advantage of the privileges without the knowledge of system administrators. Elevation of privilege threats include those situations where an attacker is allowed more privilege than should properly be granted, completely compromising the security of the entire system and causing extreme system damage. Here the attacker has effectively penetrated all system defenses and become part of the trusted system itself and can do anything.
You can use this acronym when evaluating your system at each point of your architecture to see what threats exist. There are also other threat modeling methodologies that can be used.8 As you look at the data flow diagram in Figure 6-2, you can see the boundary that exists between the client application and the API gateway. An API gateway is often located at the edge of our network and can also be internet-facing, as you learned in “Where Is an API Gateway Deployed?”. You are going to explore a number of different threats related to the API gateway and learn how this can be used to protect your system against many of the common API vulnerabilities. If you protect your system at the edge, the risks can often be reduced throughout your system, but this is not always the case. You will learn more about the move from zonal architecture, where traffic inside your security perimeter is treated differently than traffic outside, toward zero-trust models, where traffic is constantly re-authenticated, in “From Zonal Architecture to Zero Trust”. Your case study security goals are quite specific: the Attendee API should be prepared for external consumption, and to achieve this we will ensure that each process mitigates the OWASP API Security Top 10 issues. As this is a direct objective, the DFD can be used to map data flows to the issues and vulnerabilities listed on the OWASP site. However, typically a threat modeling objective may be something like “Prevent data leakage of PII to conform with GDPR,” or “Provide 99.9% availability for APIs to fulfill contractual obligations.” This second objective may not appear to be related to security, however you will want to keep DoS at the forefront of your mind, as not fulfilling this obligation, even when under a DoS attack, could result in a financial penalty. Let’s now review the system and apply STRIDE. To highlight the OWASP API Security Top 10, the threats will be grouped under the applicable STRIDE value. This is to showcase both the application of STRIDE and the OWASP API Security Top 10 along with their mitigations. When you are identifying threats in your own architecture, it is recommended you apply STRIDE to each process and connection—this is known as STRIDE per element.
Spoofing Spoofing is when a person or program is able to masquerade as another person or program. To mitigate this, you will want to authenticate any requests that are made and ensure that they are legitimate. Within the OWASP API Top 10, one of the security issues is Broken User Authentication. This is definitely related to the spoofing category, so you are going to want to ensure that the authentication flow is not broken. To learn more about this, “Authentication” provides information and an example using the case study.
Tampering Next in the STRIDE methodology is “tampering,” with the goal that users or clients should not be able to modify the system, application, or data in an unintended manner. For example, it should not be possible that a bad actor can modify the Attendee service by redirecting traffic intended for the Attendee service to an external location, or by updating attendee user data inappropriately. There are two primary ways that tampering occurs: through payload injection and mass assignment.
Payload injection Payload injection occurs when a bad actor attempts to inject a malicious payload into the request made to an API or application. Note that in the OWASP Security Top 10, this relates not only to the commonly known SQL injection but also to injection for any user input. In the case study, you can aim to prevent injection attacks early in the request handling chain, by using the API gateway to validate that the request made conforms to a defined contract or schema. Any request that does not fulfill the contract can be denied or the corresponding traffic dropped. This approach is described in “Practical Application of OpenAPI Specifications”. Increasingly, OpenAPI Specifications are used for validating HTTP requests. It is worth mentioning that although input validation is valuable when conducted at the API gateway, it does not mean you can omit further input validation and sanitization within the backend services; trust, but verify! An example of this for the Attendee service would be receiving the following POST request with this sample payload to create a user: POST /attendees { "name": "Danny B", "age": 35, "profile": "Hax; DROP ALL TABLES; --" } The OpenAPI Specification for the Attendee API defines that name should only accept letters, age accepts positive integers, and profile accepts letters, numbers, and special characters in the value (because it is for the user to write a little about themselves). The API gateway, which in this case is performing the input validation, will inspect the payload and only let it pass if the input validation is successful. Even if the input validation passes, the Attendee API should still sanitize the input to prevent an attack. The Attendee service would use prepared statements when communicating with the database. It is important to have multiple lines of defense in case one of them fails.
Mass assignment Modifiable properties that are bound to database entities are vulnerable to being inappropriately changed. They can be exploited by the vulnerability known as mass assignment. This is an important case to consider, particularly if your underlying application uses the Active Record pattern9 or some form of automated entity database serialization/deserialization, as often provided by object-relational mapping (ORM) frameworks. Let’s examine a hypothetical case for our Attendee API. Imagine that there is a property called devices that is returned when making a request for an attendee. This property is designed to be an externally read-only list of devices that the attendee has used to connect to the API, and this should only be updated by the attendee application code. A bad actor makes a GET request for an attendee (/attendees/123456) and receives the following response: { "name": "Danny B", "age": 35, "devices": [ "iPhone", "Firefox" ] } Now the bad actor issues a PUT request to the Attendee API to update the age attribute, and they also maliciously attempt to update the devices list: PUT /attendees/123456 { "name": "Danny B", "age": 36, "devices": [ "vulnerableDevice" ] } Any data in the devices list should be ignored when the entity is saved to the database. Mass Assignment is typical where client input data is bound to internal objects without thought of the repercussions, which is often a consequence when exposing a database API as a web-based API. In Chapter 1 the concerns of exposing an underlying data model are discussed from a usability point of view, which provides additional reasons not to do this. This vulnerability is not something that can typically be solved at the API gateway level; instead, this must be guarded against within the API implementation itself.
Repudiation According to STRIDE, a repudiation attack happens when an application or system does not adopt controls to properly track and log users’ actions, which permits malicious manipulation or forging the identification of new actions. For many requests that are made to an API, it is important to understand the details of the request, the payload, and the response generated (and corresponding internal actions). In certain regulatory or compliance use cases, you may need to arbitrarily inspect what was in an exchange. If a request can be repudiated—i.e., there is no proof of what the attacker has done—then the attacker can reject or disagree that they have tried to perform any such malicious action. This is why repudiation threats (the “R” in STRIDE) are included in STRIDE methodology. To identify requests that are passing through your system and to understand what is happening, you need to add logging and monitoring. Insufficent logging and monitoring is a vulnerability in the OWASP API Top 10. With all requests from users flowing through the API gateway, this is an obvious centralized point to monitor the traffic and to log the requests and responses. Many API gateways will provide this functionality out-of-the-box, but you need to understand how to store, search, and extract this information, particularly over the course of time. As with any disaster recovery and business continuity (DR/BC) capabilities, logging and monitoring must be regularly verified in order to ensure that you are capturing what is expected.
Information disclosure Information disclosure is the “I” in STRIDE, and this is focused on not exposing information that should only be used internally or kept secret. Two common antipatterns in this category of threat include excessive data exposure and improper assets management.
Excessive data exposure The OWASP API Top 10 Excessive data exposure is focused on making sure data is not exposed inappropriately. As a hypothetical scenario, imagine the Attendee service holds PII such as a passport number. When designing your API, it is important to prevent the inappropriate exposure of this data. It is all too easy to make naive assumptions about how an API will be called, especially as a system evolves over time. APIs that were initially intended only for internal consumption can be exposed publicly (with good intentions), or a previous API that was only accessible to a trusted client application can be opened to public consumption. If an API is called via a web application, it is easy to examine requests, responses, and corresponding payloads via the developer tools included within modern web browsers. For example, any user information request made to the Attendee API may accidentally return passport information: { "values": [ { "id": "0", "name": "Danny B", "age": 65, "email", "danny.b@masteringapis.com", "passport": "Abc12408NJUILM" }, { "id": "1", "name": "Jimmy G", "age": 93, "email": "jimmy.g@masteringapis.com", "passport": "ZYX123ASJJ0072M" } ] } It is possible to perform response validation in an API gateway. However, it is the responsibility of those building the API to know what they are exposing and to not expose sensitive data that should be private. Any implementation in an API gateway should be seen as the verification of last resort (or part of a “belt and braces” approach to verification). You will also need to ensure that you don’t leak sensitive data back to calling clients, such as the versions of a web server being used or an application stack trace that has been generated as a result of a crash.
Improper assets management Improper assets management typically occurs as your systems evolve, and the organization loses track of which APIs (and which versions) are exposed or which APIs were designed for internal consumption only. As a hypothetical example with the Attendee API, it could be possible to have multiple versions of the API deployed into production, with an early version of the API exposing all attendee properties by default. As the data model evolves, several private fields that contain PII are added, and new versions of the Attendee service remove this information when the API is queried. Even if the old version of the Attendee service does not fully function, it can still be used to extract the additional information contained in the data model. A hypothetical example for the Attendee service is that the /beta/attendees endpoint is publicly exposed. This early version was exposed for some testing and then forgotten about. As there is no proper management over exposed assets, it is not noticed, but an attacker could try to call the endpoint. If all API traffic is managed through your gateway, you should have a registration within it to know what exists. You can also examine requests and look for anomalies of requests called to unexpected endpoints. To counteract this problem, an API management or developer portal platform can be used to catalog and track all APIs deployed to production. Many API Management solutions include this functionality as standard, as it is seen as a vital component to manage the lifecycle of APIs.
Denial of service Within the STRIDE methodology, the “D” is focused on denial of service (DoS). A DoS attack attempts to overwhelm a system or any of its defenses for malicious purposes. For example, a firewall that becomes overloaded may default to allowing all traffic, which enables an attacker to make malicious calls that previously would have been blocked. Or a bad actor may simply want to deny availability of a critical service, such as a voting website. By overloading the system with traffic, no legitimate requests can be made and no user can vote. The OWASP API Top 10 has a security issue that covers DoS extensively. The Attendee API needs to meet your scalability demands, but it should also guard against becoming overloaded with traffic. To accomplish this, you can use the techniques of rate limiting and load shedding. Malicious DoS attacks or Distributed DoS attacks are best handled by specialist service providers, software, or hardware. For example, many content delivery network (CDN) providers include DoS prevention by default, and most public vendors offer a similar service that can be attached to public domain names and IP addresses.
Warning A denial of service can occur by accident, such as “friendly fire DoS,” that is caused by your own systems. As systems evolve, it is not uncommon to accidentally introduce circular dependencies, and given the right conditions, this can involve internal services calling each other’s, APIs in an infinite loop. This is why implementing rate limiting and error monitoring on internal API calls can be invaluable!
Rate limiting and load shedding Rate limiting, as the name suggests, limits the number of requests that can be made to your API over a period of time.10 The use of rate limiting typically refers to rejecting traffic based on properties of individual requests (too many from a given user, client application, or location). Load shedding refers to rejecting requests based on the overall state of the system (database at capacity, no more worker threads available). By default, many applications, web servers, and API gateways do not implement rate limiting or load shedding and the corresponding failure modes may be undefined. Performing load testing can provide insight into the limits, breaking points, and visible behavior.
Warning It is important to understand if your API gateway and other edge security tools have “fail open” or “fail closed” polices. Fail open policies will continue to permit access to your services even if there are failure conditions. A hypothetical example is that in medical emergency services, it is more important to serve information about a patient’s medical history than to authenticate the request. A fail close policy is when connections will be blocked in failure conditions. There is no single correct implementation, and the default should meet your requirements. For example, the majority of financial APIs would want a fail closed policy by default, whereas a public weather service may implement a fail open policy.For the case study, the most appropriate location to implement rate limiting would be the API gateway. To perform rate limiting, you will typically want to identify the originator of each request (or set of requests on aggregate). Example properties include IP address, geo-location, or a client ID that is sent by the client. You may not want to limit on an incoming property and instead treat all requests as being equal. Once a request property has been selected (none, or otherwise), a strategy needs to be applied to perform the limiting. The most common examples include: Fixed window A fixed limit within a period, e.g., 2,400 requests per day.Sliding window A limit within the last period, e.g., 100 requests within the last hour.Token bucket A set number of total requests are allowed (bucket of tokens) and each request takes a token when a request is made. The bucket is refilled periodically.Leaky bucket Like the Token bucket, however, the rate at which requests are processed is a fixed rate; this is the leak of the bucket.
You can see rate limiting enforcement in Figure 6-4.
Figure 6-4. Rate limiting example with the API gateway
An example of load shedding is shown in Figure 6-5.
Figure 6-5. Load shedding example with the API gateway
Elevation of Privilege The final letter “E” in STRIDE is focused on “Elevation of Privilege.” This occurs when a user or application finds a way to perform a task that is outside the scope of what should be allowed given the current security context—e.g., a user is able to execute tasks that are only meant to be executed by an administrator. The two OWASP Security Top 10 that relate to this are: Broken Object Level AuthorizationBroken Function Level Authorization
These are both focused on enforcing authorization and ensuring that requests to your API are entitled to perform the operation. This was covered in “Authorization Enforcement”.
Security misconfiguration Security misconfiguration is not limited to one of these STRIDE categories, as misconfiguration can happen in a range of places, such as information disclosure, where a permission is incorrectly assigned, or within denial of service and a rate-limiting policy is incorrectly set to fail open. Security misconfiguration is focused on ensuring that the security that you have in place is not incorrectly configured, and it is another piece that you must think about when evaluating each element of STRIDE for threats. It is a truism that having misconfigured security can be worse than having no security at all, as users behave very differently when they believe their actions and data are not secure. There are certain features of security that you are most likely always going to want, such as Transport Layer Security (TLS), and others that may be bespoke to an API or a setup, such as IP allowlisting.11 Within our case study, the API gateway is a key place where security misconfiguration could have a disastrous effect. Extra attention must be paid to its configuration as the API gateway is acting as the “front door.”
TLS termination TLS will ensure that the traffic that you receive has not been intercepted and modified. Also, TLS certificates provide information about the owner of a domain, so you can be confident in who you are contacting. As the API gateway deals with all incoming traffic, TLS can be enabled here. Having a centralized location to manage the external TLS certificates for incoming requests is also convenient. This, in comparison to not using a gateway, where TLS certificates need to be added to each web server, proxy, and application that is handling request traffic, is more difficult to manage and more likely prone to error. It is important to use a modern protocol and strong encryption, and, at the time of writing, using TLS 1.2 or later is recommended due to known issues with earlier versions of this protocol.12
Cross-Origin Request Sharing (CORS) CORS is an HTTP-header-based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading resources. Supporting CORS is a core requirement for any modern web browser, and for security reasons, browsers restrict cross-origin HTTP requests initiated from scripts. CORS works by the web browser performing “preflight” requests to see if it is allowed to make the desired call. You can explore this by checking the “Developer Tools” features of a browser. In the “Network Calls” section, you can typically see the HTTP Options requests; these are commonly CORS requests.13
Security directive hardening A request to an API endpoint can contain an arbitrary payload, including headers and a data payload. Although all genuine requests will correspond with your expected contract, an attacker can add unknown, incorrect, or malformed headers and data in an attempt to gain access or otherwise compromise your system. Actions need to be taken to mitigate this. In our case study, for example, you will want to think about implementing an HTTP header allowlist in the API gateway and removing all invalid HTTP headers. An attacker could send through additional HTTP headers to the Attendee API like X-Assert-Role=Admin or X-Impersonate=Admin. The attacker would hope that these headers will not be removed and are used internally, which may give some extra privileges.
Step 5: Evaluate Threat Risks When you perform your own threat modeling and end up with a list of threats, it is important to understand the priority of fixing them. This is what Step 5 of the threat modeling process is about. To evaluate threats, you can employ a qualitative risk calculation known as DREAD. Like STRIDE, DREAD was developed at Microsoft. This methodology provides you with an approach to start adding risk values to threats. Although DREAD is no longer used by Microsoft, it is still used by many companies and promoted as a useful way to establish a metric on the risk of a threat. DREAD has a simple scoring system based on the underlying acronym: Damage How bad would an attack be?Reproducibility Can an attack be easily reproduced?Exploitability How easy is it to mount a successful attack?Affected Users How many users are impacted?Discoverability What is the likelihood of this threat being discovered?
Each threat is scored against these DREAD categories, where each category is scored from 1–10. The risk value assigned to a threat is (Damage + Reproducibility + Exploitability + Affected User + Discoverability) / 5. In this example for our case study, you will look at the threat shown in Figure 6-6. This threat is a DDoS attack against the API gateway where no rate limiting is in place.
Figure 6-6. Data flow diagram TCP spoofing threat
Here is the ranking of this threat: Damage: 8 There is no rate limiting in place. This is a serious cause for concern as it allows anyone to send as many requests to the API gateway as they like, and potentially overload it, making it unusable.Reproducibility: 8 Calling the API gateway repeatedly with many requests every second will start to degrade and eventually stop the gateway from working.Exploitability: 5 The attacker can be outside our network to start attempting to run a DoS attack. The API gateway first checks the authentication and authorization to enforce the request. This means that the request must come from one of our legitimate and known client applications that integrate with our system.Affected Users: 10 This can have devastating effects because if the gateway is unavailable, it will affect all our users.Discoverability: 10 This is trivial to discover for anyone wanting to exploit and cause damage to our system.
The total score is (8 + 8 + 5 + 10 + 10) / 5 = 8.2. It is worth noting that the values assigned to the risk are subjective. To get a somewhat consistent rating, for each category you should define what the values mean—for example, if all users are affected, the score is 10; if all internal or all external users are affected, the score is 7; if half of a group is affected, the score is a 3; and if no one is affected, the score is 0. For the case study, all the threats identified are collected, scored, and then prioritized. In this case the highest-priority item is the lack of DDoS protection for the API gateway. As you identified in this section of the chapter, the mitigation to this issue is to implement rate limiting and load shedding for within the API gateway.
Other Risk Evaluation Tools There are other ways to evaluate threats—one of them is DREAD-D (pronounced Dread minus D). In the DREAD risk calculation, one of the D’s is Discoverability, which in some cases could be security through obscurity, which is a terrible way to protect any data. So the Discoverability element is dropped; this why it is called DREAD-D. Another tool that can be used is the Common Vulnerability Scoring System (CVSS), which can be used to measure the severity (i.e., the damage) of an exploited vulnerability. CVSS is used by NIST to evaluate CVEs, so if you ever look at a CVE, a CVSS can be found. For example, you can see this looking at the Log4J CVE and the NIST CVSS.
Step 6: Validation The sixth and final step of the threat modeling process is to validate that your security objectives are complete and ask if another review is needed. As part of threat modeling, you should have evaluated all the threats that are discovered and identified and taken action to mitigate the risks. You also want to ensure that you have completed the security objectives that you set out at the beginning of the threat modeling exercise. Threat modeling should be a recursive process with each run through the process identifying previously unknown issues. You should also periodically and continually run the threat modeling process, especially when adding new functionality to the system, but also as the external threat environment continually evolves. Threat modeling is a skill and it takes time to learn the process itself, and it is also time-consuming. However, as with any skill, the more it is used and integrated into your regular workflow, the easier it gets.
Summary In this chapter you have learned how to conduct a threat modeling exercise, both against the case study and also how to apply it to your own systems and APIs: There are strong financial penalties and reputational damage for failing to secure APIs.Threat modeling of an API-based system typically begins by creating a data flow diagram (DFD). Automated tooling can be used in order to rapidly analyze and identify potential threats.You don’t need to be a security expert to conduct threat modeling, and a key skill is “thinking like an attacker.”The process of threat modeling includes: identifying your objectives, gathering the right information, decomposing the system, identifying threats, evaluating the risk of those threats, and validating the results and actions.The OWASP API Security Top 10 is an excellent resource to understand the threats you can expect.The STRIDE methodology focuses your action on the threats of spoofing, tampering, repudiation, information disclosure, denial of service, and elevation of privilege.The DREAD methodology can be used to calculate a qualitative risk metric that can help you prioritize which threats to mitigate first.Within an API-based system, an API gateway can often provide high-level mitigation to risks that have been identified. However, as systems become more distributed, you should always consider individual service implementations and interservice communication.
You have seen a variety of threats that exist and ways to mitigate them. However, when you are returning data to the API consumer, you want to ensure that they are who they say they are, and the API consumer can only perform actions that they have permissions for. To see how you identify who the callee is and what they can do, you will take a deeper dive into authentication and authorization in the next chapter.
1 Ideally security should “start left” to bring security in as a foundation. 2 For an exhaustive reference and description of ways to perform threat modeling, please refer to Threat Modeling by Izar Tarandach and Matthew J. Coles (O’Reilly). 3 Individuals like Edward Snowden and TV shows like Mr. Robot have increased security conversations in the general public. 4 For a full breakdown of DFDs, visit the OWASP DFD introduction page. 5 You can find the Microsoft Threat Modeling Tool here and explore other options via the OWASP Threat Dragon GitHub repo. 6 The definitions used come from the paper “The threats to our Products” (download) written in 1999 by Loren Kohnfelder and Praerit Garg, the creators of STRIDE. 7 Though this definition is about individual machines, the context of what a denial of service attack is, is still the same today. It’s about taking resources offline. 8 Two additional methodologies include P.A.S.T.A and Trike. 9 The Active Record pattern is the practice of exposing a data object and its functions, which more or less map to the underlying database model. 10 One of the authors, Daniel, has written a series of articles about rate limiting and its application to API gateways. The first article of the series is available online at: “Part 1: Rate Limiting: A Useful Tool with Distributed Systems”. 11 IP allowlists are a literal list of IPs that are allowed to connect to your system. If the IP that connects is not in that list, then the request is rejected. 12 Most commercial API gateways will by default only allow current versions of TLS to be used, so you will need to enable weaker versions with known vulnerabilities if this is required. 13 To read a full explanation of CORS, you can take a look at this article by Mozilla. 