Chapter 2. Testing APIs

Chapter 1 covered the different types of APIs and the value that they provide to your architecture. This chapter closes out the Designing, Building, and Testing APIs section of this book by reviewing approaches to testing APIs. The new Attendee API that was extracted within the Introduction should obviously be tested and validated. We believe that testing is core to building APIs. It helps provide a high level of confidence to you that your service is working as expected, which will help you deliver a quality product to consumers of your API. It is only by testing your API under varying conditions that you will gain the confidence that it is operating correctly. When building APIs, as with creating any product, the only way to verify that the product works as expected is to test it. In the case of a mouthguard, this can mean stretching, hitting, pushing, and pulling the product, or even running simulations.1 As discussed in “Specifying REST APIs Using OpenAPI”, an API should not return anything that differs from what is documented. It is also frustrating when an API introduces breaking changes or causes network timeouts due to the large duration of time to retrieve a result. These types of issues drive customers away and are entirely preventable by creating quality tests around the API service. Any API built should be ready to fulfill a variety of requirements, including sending useful feedback to users who provide a bad input, being secure, and returning results within a specified service-level objective (SLO) based on our service-level indicators (SLIs) that are agreed.2 In this chapter we will introduce the different types of testing that you can apply to your API to help avoid these issues from occurring. We will highlight the positives and the negatives of each type of testing, so you can decide where best to invest your time. We are going to focus on testing APIs and where we believe that you will gain the most value; we will not be covering generic testing of services. The chapter will contain additional resources for those readers seeking to gain a significantly more in-depth and specialist knowledge about testing.
Conference System Scenario for This Chapter In “Attendees Evolution ADR”, we explained the reasons to separate the Attendee API from the rest of the conference system. The separation of the Attendee API introduces new interactions. The Attendee API will be used by the external CFP system and legacy conference system, as is shown in Figure 2-1. You will spend this chapter covering the testing needed for the Attendee service and how testing can help verify the interactions between the legacy conference system and the Attendee API. As a collective we have seen enough APIs that become inconsistent or produce accidental breaking changes as new releases are made, and this is primarily due to a lack of testing. For the new Attendee API it is important to ensure that it avoids these pitfalls by providing confidence that the correct results will always be returned, and the only way this can happen is by investing in the right levels of testing.
Figure 2-1. Scenario for the chapter
Testing can be applied at different levels of an API, starting with the individual building blocks that make up the service, going all the way to verifying that it works as part of the entire ecosystem. Before showing you some tools and frameworks that are available for API testing, it is important to understand the strategies that can be used.
Testing Strategies Testing is important; it ensures that you are building a working application. However, you don’t want something that just works, you want something that also has the right behavior. Realistically, though, you have limited time and resources to write tests, so you will want to ensure that you are not wasting cycles writing tests that provide little to no value. After all, the value for customers is when you are running in production. Therefore, you need to be smart about deciding upon the coverage and proportions of the types of tests you should be using. Avoid creating irrelevant tests, duplicating tests, and any tests that are going to take more time and resources than the value they provide (i.e., flaky tests). Not all the testing that is introduced needs to be implemented to be able to release an API, as it may not be feasible due to time constraints and business demands. To guide you to getting the right balance and the right tests for your case, we will introduce the test quadrant and test pyramid. These will give you focus on identifying the testing you should be implementing.
Test Quadrant The test quadrant was first introduced by Brian Marick in his blog series on agile testing. This became popularized in the book Agile Testing by Lisa Crispin and Janet Gregory (Addison-Wesley). The technology side of building an API cares that it has been built correctly, that its pieces (e.g., functions or endpoints) respond as expected, and that it is resilient and continues to behave under abnormal circumstances. The business cares that the right service is being developed (i.e., in our case, that the Attendee API provides the right functionality). To clarify, the term “the business” means someone who has a clear understanding of the product and the features and the functionality that should be developed; they need not have a technical understanding. The test quadrant brings together tests that help technology and business stakeholders alike—each perspective will have different opinions on priorities. The popular image of the test quadrant is shown in Figure 2-2.
Figure 2-2. Agile Test Quadrants from Agile Testing (Addison-Wesley) by Lisa Crispin and Janet Gregory
The test quadrant does not depict any order. The quadrants are labeled for convenience and this is a common source of confusion that Lisa describes in one of her blog posts. The four quadrants can be generally described as follows: Q1 Unit and component tests for technology. These should verify that the service that has been created works, and this verification should be performed using automated testing.Q2 Tests with the business. These ensure what is being built is serving a purpose. This is verified with automated testing and can also include manual testing.Q3 Testing for the business. This is about ensuring that functional requirements are met and also includes exploratory testing. When Figure 2-2 was originally created, this type of testing was manual; now it is possible to perform automated testing in this area as well.
Q4 Ensuring that what exists works from a technical standpoint. From Q1 you know that what has been built works; however, when the product is being used, is it performing as expected? Examples of performing correctly from a technical standpoint could include security enforcement, SLA integrity, and autoscaling.
The left side of quadrant (Q1, Q2) is all about supporting the product. It helps guide the product and prevent defects. The right side (Q3, Q4) is about critiquing the product and finding defects. The top of the quadrant (Q2, Q3) is the external quality of your product, making sure that it meets your users’ expectations. This is what the business finds important. The bottom of the quadrant (Q1, Q4) is the technology-facing tests to maintain the internal quality of your application.3 The test quadrant does not say where you should start testing; it helps guide you on the tests that you might want. This is something that you must decide and should be based on the factors important to you. For example, a ticketing system must handle large traffic spikes, so it may be best to start with ensuring that your ticket system is resilient (e.g., performance testing). This would be part of Q4.
Test Pyramid In addition to the test quadrants, the test pyramid (also known as the test automation pyramid) can be used as part of your strategy for test automation. The test pyramid was first introduced in the book Succeeding with Agile by Mike Cohn. This pyramid illustrates a notion of how much time should be spent on a given test area, its corresponding difficulty to maintain, and the value it provides in terms of additional confidence. The test pyramid at its core has remained unchanged. It has unit tests as its foundation, service tests in the middle block, and UI tests at the peak of the pyramid. Figure 2-3 shows the areas of the test pyramid you will explore.
Figure 2-3. The test pyramid, showing the proportion of tests desired
The test automation pyramid shows the trade-offs that exist in terms of confidence, isolation, and scope. By testing small parts of the codebase, you have better isolation and faster tests; however, this does not give confidence that the whole application is working. By testing the entire application in its ecosystem, the opposite is true. The tests give you more confidence that the application is working, but the scope of the test will be large as many pieces will be interacting together. This also makes it more difficult to maintain and slow. The following defines each of the core elements of the test pyramid: Unit tests are at the bottom of the pyramid; they form the foundation of your testing. They test small, isolated units of your code to ensure that your defined unit is running as expected.4 If your test is going to escape the boundaries of your unit, you can use test doubles. Test doubles are objects that look like real versions of an external entity; however, they are under your control.5 Because unit tests form the foundation of your pyramid, there should be more unit tests than any other type of test; we recommend using TDD as a practice.6 TDD is about writing tests before you write the logic. Unit tests fit into Q1 of the test quadrant and are used to provide quality to the internals of the application. Unit testing will not be covered further as we will be focusing on tests that verify your API from an external consumer standpoint as opposed to the internals of an API.Service tests make up the middle tier of the pyramid. They will provide you with more confidence that your API is working correctly than unit tests, though they are more expensive. The expense comes from the tests having a larger scope and less isolation, which incurs a higher maintenance and development cost. Service tests include some of the following cases: the verification that multiple units are working together, that behavior is as expected, and that the application itself is resilient. Therefore, service tests fit into Q1, Q2, and Q4 of the test quadrant.UI tests sit at the top of the test pyramid. In the old days a majority of applications being built for the web were LAMP stacks, and the only way to test your application from the front to the backend was through the Web UI. There is a UI with APIs: it is just not graphical, so these tests will now be referred to as end-to-end tests. They cover the same ground of a request flowing from a start to an end point but do not necessarily imply or assume that traffic originates from a Web UI. End-to-end tests are the most complex. They have the largest scope and are slow to run; however, they will verify entire modules are working together so they provide lots of confidence. End-to-end tests will generally sit in Q2, Q3, Q4 of the quadrant. Tooling for testing has improved and become more advanced, and it is now making more and more of Q3 available for automation.
One type of test is not better than another—the test pyramid is a guide to the proportions of each type of testing you should aim to implement. It can be tempting to ignore the test pyramid and concentrate on end-to-end testing as this gives a high degree of confidence. However, this is a fallacy and instead gives a false sense of security that these higher-level tests are of higher quality/value than unit tests. The fallacy gives rise to the ice cream cone representation of testing, which is the opposite of a test pyramid. For a robust argument on this topic, please read Steve Smith’s blog post “End-to-End Testing considered harmful”. You may also consider implementing other proportions of tests, though it is not recommended. Martin Fowler wrote an updated piece on testing shapes and covered why he feels that testing that is guided by any shape other than the test pyramid is incorrect.
ADR Guideline for Testing Strategies To help you decide on the testing strategy that you should use, the ADR Guideline in Table 2-1 should help you make an informed decision. Table 2-1. ADR Guideline: Testing strategies Decision When building your API, which testing strategy should be made part of the development process?Discussion Points Do all parties that have a stake in the API have the time and the availability to regularly discuss how the API should be working? If you are unable to effectively communicate with the stakeholders, you could end up stalling your product waiting for a decision to be made. Are the skills and experience available to effectively use these testing strategies? Not everyone has used these practices before, so you need to weigh if you have the time resources to train everyone on them. Are there other practices within your workplace that are recommended and should be used? Sometimes there can be internal strategies to building software that work for an organization or are required due to the nature of the business.Recommendations We recommend using test quadrants and the test pyramid. The test quadrant is very valuable to ensure that your customers are getting the right product. The test quadrant coupled with the test pyramid will help you build a great API. We do recognize that using the test quadrant in its truest form by having someone readily available from the business to help guide your testing is not always possible. However, at a minimum, use the test pyramid as this concentrates the automated side of the test quadrant. This at the very least will ensure that you find bugs early in your development cycle. Whatever the case, you will always need someone to help guide the product direction.
Contract Testing Contract testing has two entities: a consumer and a producer. A consumer requests data from an API (e.g., web client, terminal shell), and a producer (also known as a provider) responds to the API requests, i.e., it is producing data, such as a RESTful web service. A contract is a definition of an interaction between the consumer and producer. It is a statement to say if a consumer makes a request that matches the contract request definition, then the producer will return a response that matches the contract response definition. In the case of the Attendee API, it is a producer and the consumer is the legacy conference system. The legacy conference system is a consumer as it is calling the Attendee API.7 So why use contracts? What do they offer you?
Why Contract Testing Is Often Preferable As you learned in “Specifying REST APIs Using OpenAPI”, APIs should have a specification, and it is important that your API responses conform to the API specification that you have laid out. Having a written definition of these interactions that must be adhered to by the producer ensures that consumers can keep using your API and makes it possible to generate tests. The contract defines what a request and response should look like and these can be used to verify that the producer (the API) is fulfilling the contract. If you break a contract test, then it means that the producer is not fulfilling the contract anymore, which means that consumers will be broken. As the contract has the response definition, it is also possible to generate a stub server.8 This stub server can be used by consumers to verify that they can call the producer correctly and parse the response from the producer. Contract testing can be performed locally—it is not required to launch additional services, which makes it part of your service tests. Contracts will evolve and the consumers and producers pick up these changes as they are made available, which ensures that they are able to continually integrate with the latest contract. There is already a lot of value here about why you would want to use contracts. Additionally, contract testing has a well-developed ecosystem. There are established methodologies that guide what the contract should be, as well as frameworks and test integrations to generate contracts and provide effective ways to distribute them. We believe that contracts are the best way to define interactions between the service you implement and a consumer. Other tests are important and should be implemented as well, but these offer the most bang for the buck.
Note It is important to note that contract testing is not the same as saying that an API conforms to a schema. A system is either compatible with a schema (like OpenAPI Spec) or it is not; a contract is about a defined interaction between parties and provides examples. Matt Fellows has an excellent piece on this titled “Schema-based contract testing with JSON schemas and Open API (Part 1)”.
How a Contract Is Implemented As mentioned, a contract is a shared definition of how a producer and consumer interact. The following example shows a contract for a GET request to the endpoint /conference/{conference-id}/attendees. It states that the expected response has a property called value that contains an array of values about the attendees. In this sample definition of a contract, you can see that it is defining an interaction, which is used to generate the tests and stub server: Contract.make { request { description('Get a list of all the attendees at a conference') method GET() url '/conference/1234/attendees' headers { contentType('application/json') } } response { status OK() headers { contentType('application/json') } body( value: [ $( id: 123456, givenName: 'James', familyName: 'Gough' ), $( id: 123457, givenName: 'Matthew', familyName: 'Auburn' ) ] ) } } In Figure 2-4 you see how the generated tests are used by the consumer and producer.
Figure 2-4. Generated stub server and tests from a contract
Warning It is tempting to use contracts for scenario tests. For example: Step 1: add an attendee to a conference. Step 2: get the list of attendees of the conference and check that the attendee was added correctly.Frameworks do support this but also discourage it. Contracts are about defining interaction; if you wish to test this type of behavior, then use component tests.A key benefit of using contracts is that once the producer agrees to implement a contract, this decouples the dependency of building the consumer and producer.
Tip We have used generated stub servers to run demos for stakeholders. This was useful as the producer was still implementing the logic; however, they had agreed to the contracts.The consumer has a stub server to develop against and the producer has tests to ensure that they are building the right interaction. The contract test process saves time, as when both the consumer and producer are deployed, they should integrate seamlessly.
Note The generated tests need to be executed against your running API (producer). When your API launches, you should use test doubles for external dependencies. You do not want to be testing integrations with other services as part of your generated contract tests against the consumer.To understand how contracts are agreed upon, let’s look at the two main contract methodologies.
Producer contracts Producer contract testing is when a producer defines its own contracts. This practice is commonly utilized when your API is being used outside your immediate organization (i.e., external third parties). When you’re developing an API for an external audience, the API needs to maintain its integrity, because the interface cannot make breaking changes without a migration plan, as you learned in “API Versioning”. Though interactions will be updated and improved, no individual consumer is likely to be able to ask for changes that affect the whole API and receive a quick change, because these changes need to be carefully orchestrated. A real-world example of such an API is the Microsoft Graph API. Microsoft has thousands of consumers of this API from companies all over the world. Having companies or individuals adjust contracts for the Graph API with what they believe the contract should look like isn’t feasible. That is not to say that changes should not be suggested to Microsoft, as they definitely are. However, even if a change is agreed to it will not be made quickly as the change will need to be verified and tested carefully. If the Attendee API is going to be made available for public consumption, then the same concerns occur. What is important for the Attendee API is to use contracts to ensure that the interactions do not diverge and that the data returned is consistent. Another reason to use producer contracts is that it is easier to get started. It is a good way to introduce contracts to your APIs. Having contracts is far more beneficial than not having them. However, when consumers and producers are both in the same organization, we suggest that you use the consumer-driven contracts methodology.
Consumer-driven contracts Consumer-driven contracts (CDCs), by definition, are implemented by a consumer driving the functionality that they wish to see in an interaction. Consumers submit contracts, or changes to a contract, to the producer for new or additional API functionality. When the new/updated contract is submitted to the producer, a discussion about the change will begin, which will result in accepting or rejecting this change. CDC is very much an interactive and social process. The owners of the applications that are consumers and producers should be within reach (e.g., in the same organization as one another). When a consumer would like a new interaction (e.g., API call) or have an interaction updated (e.g., a new property added), then they submit a request for that feature.
Case study: Applying CDC In our case, this may mean that a pull request is submitted from the legacy conference system to the new Attendee API service. The request for the new interaction is then reviewed and a discussion takes place about this new functionality. This discussion is to ensure that this is something that the Attendee service should and will fulfill. For example, if a contract is suggested for a PUT request, a discussion can take place, as it may be preferable to have this as a PATCH request. This is where a good part of the value of contracts comes from: this discussion for both parties about what the problem is, and using a contract to assert that this is what the two parties accept and agree to. Once the contract is agreed to, the producer (Attendee service) accepts the contract as part of the project and can start fulfilling it.
Contracts methodology overview These methodologies should hopefully give an overview of how to use contracts as part of the development process. This should not be taken as gospel, as variations do exist on the exact steps. For example, one process may request that the consumer—when writing the contract—also creates a basic implementation of producer code to fulfill the contract. In another example, the consumer should TDD the functionality they require and then create the contract before submitting the pull request. The exact process that is put in place may vary by team. Once you understand the core concepts and patterns of CDC, the exact process that is used is just an implementation detail. If you are starting out on a journey to add contracts, you should note that there is a cost—the setup time to incorporate contracts into a project and also the cost of writing the contracts. It is worth looking at tooling that can create contracts for you based on an OpenAPI Specification.9
Contract testing frameworks It is likely that when it comes to contract testing frameworks for HTTP, you will want to look at Pact. Pact has evolved into the default contract testing framework due to the ecosystem that has been built around it and the sheer number of languages it supports. Other contract testing frameworks are available, and they can be opinionated. Pact is opinionated; it enforces that you should perform CDC and is specifically designed for that. A test is written by a consumer and that test generates a contract, which takes the form of an intermediate representation of the interaction. This language-agnostic intermediate representation is why Pact has such wide language usage. Other frameworks have differing opinions; for example, Spring Cloud Contracts does not have a strong opinion on CDC or producer contracts, and either can be achieved. This is possible as with Spring Cloud Contracts you write the contracts by hand as opposed to having them generated. Though Spring Cloud Contracts is language agnostic by using a containerized version of the product, to get the most out of it you need to be using the Spring and JVM ecosystem.10 There are options for contract testing for other protocols; it is not exclusively for HTTP communications.
API contracts storage and publishing Having seen how contracts work and methodologies of incorporating them into the development process, the next consideration becomes where contracts are stored and how they should be published. There are a few options for storing and publishing contracts and these again depend on the setup that is available to you and your organization. Contracts can be stored alongside the producer code in version control (e.g., Git). They can also be published alongside your build into an artifact repository such as Artifactory. Ultimately the contracts need to be obtainable by the producer and the consumer. The storage point also needs to allow for the submission of new contracts. The producer should have control over which contracts are accepted in the project and can ensure that undesired changes aren’t made or additional contracts are added. The downside to this approach is that in a large organization it can be difficult to find all the API services that use contracts. Another option is to store all the contracts in a centralized location to enable visibility into other API interactions that are available. This central location could be a Git repository, but the downside to this approach is that unless organized and set up correctly, it is possible and likely that contracts get pushed into a module that the producer has no intention of fulfilling. Yet another option for storing contracts is to use a broker. The Pact contract framework has a broker product that can be used as a central location to host contracts. A broker can show all contracts that have been validated by the producer as the producer will publish those contracts that have been fulfilled. A broker can also see who is using a contract to produce a network diagram, integrate with CI/CD pipelines, and provide even more valuable information. This is the most comprehensive solution available and if you use a framework that is compatible with the Pact Broker, then it is recommended.
ADR Guideline: Contract Testing To understand if applying contract testing is valid for your case and weighing the pros and cons of using contracts, the ADR Guideline in Table 2-2 should help guide you to a decision. Table 2-2. ADR Guideline: Contract testing Decision When building an API should you use contract testing and, if so, should you use consumer-driven contracts or producer contracts?Discussion Points Determine whether you are ready to include contract testing as part of your API testing. Do you want to add an extra layer of testing to your API that developers will be required to learn about?
If contracts have not been used before, then it requires time to decide how you will use them. Should contracts be centralized or in a project?Do additional tools and training need to be provided to help people with contracts?
If deciding to use contracts, then which methodology should be used—CDC or producer contracts? Do you know who will use this API?Will this API be used just within your organization?Does the API have consumers that are willing to engage with you to help drive your functionality?
Recommendations We recommend using contract testing when building an API. Even if there is a developer learning curve and you are deciding how you are going to set up your contracts for the first time, we believe it is worth the effort. Defined interactions that are tested save so much time when integrating services together. If you are exposing your API to a large external audience, it is important to use producer contracts. Again, having defined interactions that help ensure that your API does not break backward compatibility is crucial. If you’re building an internal API, the ideal is to work toward CDC, even if you have to start with producer contracts and evolve over to CDC. If contract testing is not feasible, then for a producer you need alternatives to ensure that your API is conforming your agreed interactions and provide a way that consumers can test. This means that you have to be very careful with your tests that the responses and requests match with what is expected, which can be tricky and time-consuming.
API Component Testing Component testing can be used to validate that multiple units work together and should be used to validate behavior—they are service tests in the test pyramid in Figure 2-3. An example of a component test is sending a request to your API and verifying the response. At a high level it will require that your application can read the request, perform authentication and authorization, deserialize a payload, perform the business logic, serialize the payload, and respond. That is a lot of units being tested, and it would be difficult to point to exactly where a bug could be. Where this example differs from a contract test is that you should be checking that the service had the correct behavior; for example, if this was creating a new attendee, you want to verify that the service made a call to the (mocked) database. You are not just checking the shape of the response like contract tests do. As component tests verify multiple units together, they are (normally) slower running than unit tests. Component tests should not call out to external dependencies. Like contract testing, you are not using these tests to verify external integration points. The type of tests that you want to trigger in this scope varies based on the business case; however, for APIs you would be looking to validate cases such as: Is the correct status code returned when a request is made?Does the response contain the correct data?Is an incoming payload rejected if a null or empty parameter is passed in?When I send a request where the accepted content type is XML, will the data return the expected format?If a request is made by a user who does not have the correct entitlements, what will the response be?What will happen if an empty dataset is returned? Is this a 404 or is it an empty array?When creating a resource, does the location header point to the new asset created?
From this selection of tests, you can see how these bleed into two areas of the test quadrant. This includes Q1, where you are confirming that the API being built works (i.e., it is producing results), and Q2, where you test to verify that the responses of the Attendee API are correct.
Contract Testing Versus Component Testing If contract testing is not available, you should use API component tests to verify that your API conforms to your agreed interactions, i.e., your API specification. Using API component tests to verify that your API conforms to an interaction is not ideal—for a start, it is much more likely to be error-prone and is tedious to write. You should make contracts your golden source of agreed interactions, as the generated tests ensure that the shape of your API is accurate.
Case Study: Component Test to Verify Behavior Let’s look at an example of a case for our Attendee API for the endpoint /conference/{conference-id}/attendees. This endpoint returns a list of the attendees at a conference event. For this component test, a mock is used to represent our external database dependency, and as seen in Figure 2-5, in this case that is the DAO. Some things to test this endpoint for are: Requests that are successful have response of 200 (OK)Users without the right level of access will return a status of 403 (Forbidden)When a conference has no attendees, an empty array will be returned
Figure 2-5. API Component test with mocked DAO
A library or testing framework that wraps a request client can be really useful. Here REST-Assured is used to call the Attendee API endpoint and to verify these test cases:11 @Test void response_for_attendees_should_be_200() { given() .header("Authorization", VALID_CREDENTIAL) .when() .get("/conference/conf-1/attendees") .then() .statusCode(HttpStatus.OK.value()); } @Test void response_for_attendees_should_be_403() { given() .header("Authorization", INVALID_CREDENTIAL) .when() .get("/conference/conf-1/attendees") .then() .statusCode(HttpStatus.FORBIDDEN.value()); ... } Running this type of test gives us confidence that our API is behaving correctly.
API Integration Testing Integration tests in our definition are tests across boundaries between the module being developed and any external dependencies. Integration tests are a type of service test and can be seen in the test pyramid image in Figure 2-3. When performing integration testing, you want to confirm that the communication across the boundary is correct; i.e., your service can correctly communicate with another service that is external to it. The types of things you want to verify are the following: Ensuring that an interaction is being made correctly; e.g., for a RESTful service, this may be specifying the correct URL or that the payload body is correct.Can the unit that is interacting with an external service handle the responses that are being returned?
In our case the legacy conference system needs to verify that it can make a request to the new Attendee API and can interpret the response.
Using Stub Servers: Why and How If you are using contract tests, the generated stub servers can be used to verify that the consumer can communicate with the producer. The legacy conference system has a generated stub server and can use this to test against. This will keep testing local, and the stub server will be accurate. This is the preferred option for testing an external boundary. However, a generated stub server from a contract is not always available and other options are required, as in the case of testing with an external API, such as the Microsoft Graph API, or within your organization when contracts are not used. The simplest one is to hand roll a stub server that mimics the requests and responses of the service you interact with. This is certainly a viable option, as in your chosen language and framework it is usually very easy for a developer to create a stub server with canned responses that integrate with tests. The key considerations when hand rolling a stub server is to make sure that the stub is accurate. It can be very easy to make mistakes, such as inaccurately portraying the URL or making mistakes in the response property names and values. Can you see the errors in this handtyped response?12 { "values": [ { "id": 123456, "givenName": "James", "familyName": "Gough" }, { "id": 123457, "givenName": "Matthew", "familyNane": "Auburn" }, { "id": 123456, "givenName": "Daniel", "familyName": "Bryant" } ] } This should still not put you off as this is a good solution. One of the authors had great success with this approach after a requirement for a project meant he had to hand roll a stub server for a login service. A way to avoid these inaccuracies and to ensure that requests to URLs are accurately captured along with the responses is to use a recorder. It is possible to use a tool that will record the requests and responses to an endpoint and generate files that can be used for stubbing. Figure 2-6 shows how this works.
Figure 2-6. How a consumer of the Attendee API would use a recorder to capture a request/response for test data
These generated files are mappings that can then be used for tests to accurately portray requests and responses, and as they are not hand rolled they are guaranteed to be accurate at the point of generation. To use these generated files, a stub server is launched that is capable of reading in the mappings files. When a request is made to the stub server, it checks to see if the request matches any of the expected requests in the mappings file. If it matches, then the mapped response will be returned.13 Recording calls to APIs will produce more accurate stubs than that of hand rolling a stub. If you do use recordings, then you need to make sure they stay updated and in sync; also, if you make recordings against production, you need to watch that no PII is saved into the mapping files.
ADR Guideline: Integration Testing Integration testing is important, so to help you understand what types of integration testing you need, see the ADR Guideline in Table 2-3. Table 2-3. ADR Guideline: Integration testing Decision Should integration testing be added to API testing?Discussion Points If your API is integrating with any other service, what level of integration test should you use? Do you feel confident that you can just mock responses and do not need to perform integration tests?For creating a stub server to test against, are you able to accurately craft the request and responses or should they be recorded?Will you be able to keep stub servers up-to-date and recognize if an interaction is incorrect?
If your stubs are incorrect or become out of date, this means it is possible to have tests that pass against your stub server, but when you deploy to production, your service fails to interact with the other API as it has changed.
Recommendations We do recommend using the generated stub servers from contract tests. However, if this is not available, then having integration testing using recordings of interactions is the next best option. Having integration tests that can be run locally gives confidence that an integration will work, especially when refactoring an integration; it will help to ensure that any changes have not broken anything.
Integration testing is a really useful tool; however, definitions of these interactions have issues. The main issue is that they are point-in-time snapshots. These bespoke setups do not get updated with changes. We have been using stub servers for the integrations we have looked at; however, it is possible to use a real instance of the external service to verify an integration.
Containerizing Test Components: Testcontainers It is common to build applications as containerized images, which means that many applications that your service will integrate with are also available as containerized solutions. These images can be run on your local machine as part of your testing. Not only does using local containers allow for testing communication with the external services, but also you can run the same image that is run in production. Testcontainers is a library that integrates with your testing framework to orchestrate containers. Testcontainers will start and stop and generally organize the lifecycle of containers you use with your tests.
Case Study: Applying Testcontainers to Verify Integrations Let’s take a look at two use cases where this is helpful for the Attendee API. The first case is that the Attendee API service will support a gRPC interface as well as the RESTful interface. The gRPC interface is to be developed after the RESTful interface, but there are eager developers who want to start testing against a gRPC interface. The decision is made to provide a stub server for the gRPC interface, which will be a stub that provides a few canned responses. To achieve this goal, a bare-bones application is made that fulfills this objective. This gRPC stub is then packaged up, containerized, and published. This stub can be now used by the developers for testing across a boundary; i.e., they can make real calls to this stub server in their tests, and this containerized stub server can run locally on their machine. The second use case is that the Attendee API service has a connection to an external database, which is an integration to test. The options for testing integration boundaries for a database would be to mock out the database, use an in-memory database (e.g., H2), or run a local version of the database using Testcontainers. Using a real instance of the database in your test provides a lot of value because with mocks you can mock the wrong return value or make an incorrect assumption. With an in-memory DB you are assuming that the implementation matches the real DB. Using a real instance of the dependency and it being the same version that you run in production means that you get reliable testing across a boundary, which ensures that the integration will work when going to production. In Figure 2-7 you see the structure of the test to confirm a successful integration across a boundary with a database.
Figure 2-7. Testcontainers DAO test
Testcontainers is a powerful tool and should be considered when testing boundaries between any external services. Other common external services that benefit from using Testcontainers include Kafka, Redis, and NGINX. Adding this type of solution will increase the time it takes for your tests to run; however, integration tests are usually fewer and the additional confidence that is provided more often than not is a worthwhile trade-off for additional time. Using Testcontainers raises a couple of questions. First, is this type of testing considered integration testing or is it end-to-end testing as a real instance of another service is being tested against? Second, why not just use this instead of contracts? Using Testcontainers does not make the tests end-to-end if it stays within the integration boundary. We suggest that you use Testcontainers to test integrations; ensuring that the container has the right behavior is not your job (assuming that the owner of the image is outside your domain). For example, if I issue a statement to publish a message to a Kafka broker, I should not then subscribe to the topic to check that the item published was correct. I should trust that Kafka is doing its job and subscribers would be getting the message. If you want to verify this behavior, make it part of your end-to-end tests. That is why the boundary of what you are testing matters, so the case of the DAO to the database is not end-to-end testing, because only the interactions across the boundary are validated. Testcontainers and integrating with a real service is a real boon and can add a lot of value to your testing, though they are not a replacement for contracts just because you can use a real version of a service. Working with a real instance is nice; however, contracts provide so much more than just a stub server—they provide all the testing, integration, and collaboration.
End-to-End Testing The essence of end-to-end testing is to test services and their dependencies together to verify they work as expected. It is important to validate that when a request is made, and it reaches the front door (i.e., the request reaches your infrastructure), the request flows all the way through and the consumer gets the correct response. This validation gives confidence that all these systems work together as expected. For our case this is testing the legacy conference system, the new Attendee service, and the database all together.
Automating End-to-End Validation This section concentrates on automated end-to-end tests. Automation is intended to save you time, so we will present automated testing that we believe gives you the best value. You will always need to verify that your systems work together—however, you can do this manually in a testing environment before releasing software into production.
Warning If you are building an external-facing API and you have multiple third parties that are consuming it, don’t try to copy the third-party UI and replicate how it works. Doing so will mean that you spend huge amounts of time trying to replicate something out of your domain.For end-to-end testing it is ideal is to have real versions of your services running and interacting together; however, sometimes this is not always feasible. Therefore, it is okay to stub out some entities of a system that are outside your organization’s domain and are provided by an external party. A hypothetical case would be if the Attendee service required the use of AWS S3. Relying on an external entity opens up concerns such as network issues or even the external provider being unavailable. Also, if your tests are not going to use an entity, there is no need to make it available for your test. For an end-to-end test of the Attendee service, the database and the Attendee service need to be launched, but this does not require the legacy conference system, as it is superfluous. This is why end-to-end tests sometimes require boundaries. The boundary for this end-to-end test is shown in Figure 2-8.
Figure 2-8. End-to-end test scope
Managing and coordinating multiple systems together is not easy to automate and end-to-end tests can be brittle. However, running end-to-end tests locally is becoming easier. As you have just seen in “Containerizing Test Components: Testcontainers”, containerization allows you to spin up multiple systems locally. Even though this is getting easier, you should still follow the test pyramid guidelines—end-to-end tests are at the top of the test pyramid for a reason. When writing your end-to-end tests, you should use realistic payloads. We have seen cases where tests use small and concise payloads, then when investigating why APIs are breaking it is found that the consumers are regularly sending very large payloads—larger than the buffers support. This is why your end-to-end testing needs to be representative of the way that a consumer uses your API.
Types of End-to-End Tests The end-to-end tests that you write should be driven off the requirements that are most important, as you saw in “Test Quadrant”. Within Q3 of the test quadrant, you see scenario testing. Scenario tests are a common form of end-to-end testing. They are for testing out typical user journeys and provide confidence that your service is performing correctly. A scenario test can be based around a single action or multiple actions. It is important that you are only testing core user journeys and not testing edge cases or exception testing. To help you write your tests, you can use Behavior Driven Development (BDD). This is a nice way to write your user stories as part of your business-facing tests. An example for the conference system would be that when an attendee is registered for a conference talk, the attendee count should have increased when the conference talk information is retrieved. The nice thing with scenario tests and validating these core user journeys is that you are not going to be concerned if a component is slower than in production. What is being interrogated is the correct behavior and expected results. However, you need to be more careful when running performance end-to-end tests. Performance testing, Q4 in the testing quadrant, should be deployed to a like-for-like environment of your production environment. If the two differ, you will not get results indicative of how your services are working. This does mean that you are going to need to deploy your services to this representative hardware, and depending on your resources and environment, that can be tricky. You should take this into consideration if it is going to make your tests flaky or is going to cost more development time than the return of confidence. However, this should not put you off because we have seen this type of end-to-end testing be successful. The performance tests that you write as part of your end-to-end testing should be focused on ensuring that you are still serving requests within your targeted SLOs. You want these performance tests to show you have not introduced any sudden lag to your services (e.g., accidentally adding in some blocking code). If volume is important, you want to verify that your service is able to handle the loads you expect. Some great tools are available for performance testing, such as Gatling, JMeter, Locust, and K6. Even if none of these appeal to you, others are available and in many different languages that you should be familiar with. The performance figures that you want should be driven from your business requirements. As part of your end-to-end testing, you should also ensure that your security is in place (i.e., TLS is turned on and the appropriate authentication mechanisms are in place). Security should not be turned off for these tests as it does not make it representative of a user journey, or it misrepresents metrics. End-to-end testing is more complex than any other type of testing as it takes resources to create and maintain. Though it can be a time saver over doing end-to-end manual testing, it provides confidence in the application and evidence that services were working from a technical standpoint to meet service agreements.
ADR Guideline: End-to-End Testing Knowing what to include, and whether end-to-end testing is worthwhile for your case, are important considerations. The ADR Guidelines in Table 2-4 should help you make a decision. Table 2-4. ADR Guideline: End-to-End Testing Decision As part of your testing setup, should you use automated end-to-end tests?Discussion Points Determine how complex your setup is to enable end-to-end testing. Do you have a good idea of end-to-end tests that you require and will provide value? Are there any specific requirements or more advanced end-to-end tests that you should add?
Recommendations We recommend that you do perform at a minimum end-to-end testing on core user journeys. This is going to give feedback as early as possible in your development cycle that a user could be impacted with the changes that have been made. Ideally you can run these end-to-end tests locally; however, if not, then it should be part of your build pipeline. End-to-end testing is valuable but must be balanced against the time investment you need to get it running. If it is not possible to do automated end-to-end testing, then you need to have a run book of manual tests that you can use. This run book should be used against a testing environment before a production release. This type of manual testing will considerably slow down your production releases and ability to deliver value to customers.
Summary In this chapter you have learned about the core types of testing for APIs, including what should be tested and where time should be dedicated. The key takeaways are: Stick to the fundamentals of testing and make unit testing a core of your API.Contract testing can help you develop a consistent API and test with other APIs.Perform service tests on your component and isolate the integrations to validate incoming and outgoing traffic.Use end-to-end tests to replicate core user journeys to help validate that your APIs all integrate correctly.Use the ADR Guidelines as a way to work out if you should add different tests to your API.
While we’ve given you lots of information, ideas, and techniques for testing your API, this is by no means an exhaustive list of tools available. We encourage you to do some research on testing frameworks and libraries that you may want to use, to ensure you are making an informed decision. However, no matter how much testing is done upfront, nothing is as good as seeing how an application actually runs in production. You will learn more about testing in production in Chapter 5. The next chapter will focus on exposing and managing APIs in a production setting using API gateways.
1 Matthew’s friend owns a mouthguard company and was on the receiving end of hearing about the arduous process for testing the integrity of the product. No one wants a mouthguard where the only testing takes place during the match! 2 SLOs and SLIs will be discussed in more detail in Chapter 5. 3 To learn more on agile testing, check out the books Agile Testing (O’Reilly), More Agile Testing (O’Reilly), or the video series Agile Testing Essentials. 4 The typical example of a unit in object-oriented (OO) languages is a class. 5 Test doubles include stubs, which look like real implementations of an external entity, except they return hardcoded responses. Mocks look like real implementations of preprogrammed objects, but instead are used to verify behavior. 6 Kent Beck’s book Test Driven Development: By Example (Addison-Wesley) is a fantastic resource for learning more about TDD. 7 To clarify, it is also possible that a service can be both a producer and consumer. 8 A stub server is a service that can be run locally and will return canned responses. 9 At the time of writing, there are a few projects that are available, though none are actively maintained, so it is difficult to recommend any. 10 Pact does a good job of comparing itself to other contract frameworks. 11 These testing libraries usually have a Domain Specific Language (DSL) and make it easy to analyze responses from the API. RestAssured is one such REST testing framework in Java, and the httptest package comes out of the box with Golang. Depending on the language or framework that you use, there should be something available; otherwise, creating a small wrapper around a standard client can make things considerably easier to integrate responses when writing tests. 12 Duplicate value for id and misspelled familyNane (sic). 13 Wiremock is a tool that can be used as a standalone service, making it language agnostic, although since it is written in Java there are some specific Java integrations that you can take advantage of. There are many other tools available that have a similar capability in other languages such as camouflage, which is written in TypeScript.
Part II. API Traffic Management This section explores how API traffic is managed. This includes both traffic originating externally from end users that is entering (ingressing) into your system and traffic originating internally from services that is traveling across (service-to-service) your system. In Chapter 3, where we recommend you begin your journey, you will explore using API gateway technology to manage ingress, or north–south traffic. In Chapter 4, you will learn about managing east–west traffic using the service mesh pattern. 